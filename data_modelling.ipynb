{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries needed\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "rm_data = pd.read_csv('rightnow_2023-05-17.csv')\n",
    "omt_data = pd.read_csv('omt_2023-05-18.csv')\n",
    "z_data = pd.read_csv('zoopla_2023-05-18.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2100 entries, 0 to 2099\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   transaction     2100 non-null   object \n",
      " 1   address         2100 non-null   object \n",
      " 2   bedroom         1976 non-null   float64\n",
      " 3   bathroom        1947 non-null   float64\n",
      " 4   sales_price     2100 non-null   object \n",
      " 5   rent_perMonth   1050 non-null   object \n",
      " 6   rent_perWeek    1050 non-null   object \n",
      " 7   description     2100 non-null   object \n",
      " 8   propertyType    2100 non-null   object \n",
      " 9   location        2098 non-null   object \n",
      " 10  agent           2100 non-null   object \n",
      " 11  listing_source  2100 non-null   object \n",
      " 12  listing_url     2100 non-null   object \n",
      " 13  date_type       2100 non-null   object \n",
      " 14  date            2100 non-null   object \n",
      "dtypes: float64(2), object(13)\n",
      "memory usage: 246.2+ KB\n"
     ]
    }
   ],
   "source": [
    "rm_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1886 entries, 0 to 1885\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   transaction     1886 non-null   object \n",
      " 1   address         1804 non-null   object \n",
      " 2   bedroom         1796 non-null   object \n",
      " 3   bathroom        1715 non-null   float64\n",
      " 4   sales_price     1886 non-null   object \n",
      " 5   rent_perMonth   943 non-null    object \n",
      " 6   rent_perWeek    943 non-null    object \n",
      " 7   description     0 non-null      float64\n",
      " 8   propertyType    1804 non-null   object \n",
      " 9   location        1804 non-null   object \n",
      " 10  agent           164 non-null    object \n",
      " 11  listing_source  1886 non-null   object \n",
      " 12  listing_url     1886 non-null   object \n",
      " 13  date_added      1886 non-null   object \n",
      "dtypes: float64(2), object(12)\n",
      "memory usage: 206.4+ KB\n"
     ]
    }
   ],
   "source": [
    "omt_data.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Unique ID for each data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The unique id will be crated by combining the  [[transaction,agent,address,sales_price,rent_permonth,rent_perweek]] as one attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_data['id'] = rm_data['transaction'] + rm_data[\"bedroom\"].astype(str) + rm_data[\"bathroom\"].astype(str) + rm_data[\"sales_price\"].astype(str)+ rm_data[\"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omt_data['id'] = omt_data['id'] = omt_data['transaction'] + omt_data[\"bedroom\"].astype(str) + omt_data[\"bathroom\"].astype(str) + omt_data[\"sales_price\"].astype(str)+ omt_data[\"address\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_data['id'] = z_data['id'] = z_data['transaction'] + z_data[\"bedroom\"].astype(str) + z_data[\"bathroom\"].astype(str) + z_data[\"sales_price\"].astype(str)+ z_data[\"address\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database():\n",
    "    # connect to default database\n",
    "    conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password = 1118\")\n",
    "    conn.set_session(autocommit = True)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # create sparkify database with UTF8 enconding\n",
    "    cur.execute(\"DROP DATABASE IF EXISTS socialmedia\")\n",
    "    cur.execute(\"CREATE DATABASE socialmedia\")\n",
    "    \n",
    "    \n",
    "    #close connection to default database\n",
    "    conn.close()\n",
    "    \n",
    "    \n",
    "    # connect to sparkify database\n",
    "    conn = psycopg2.connect(\"host=localhost dbname=socialmedia user=postgres password=1118\")\n",
    "    conn.set_session(autocommit = True) # set commit to automatic\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    return cur,conn\n",
    "\n",
    "cur,conn = create_database()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the already created Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull out the dataset and write query"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Use LEFT outer join to combine all the three dataset as one, remove duplicate and save the distinct data set into a new table in the database and also ouput it as csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
